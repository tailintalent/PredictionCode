{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard modules\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import h5py\n",
    "# custom modules \n",
    "import dataHandler as dh\n",
    "import makePlots as mp\n",
    "import dimReduction as dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['interactive']  = False\n",
    "###############################################    \n",
    "# \n",
    "#    run parameters\n",
    "#\n",
    "###############################################\n",
    "typ = 'AML32' # possible values AML32, AML18, AML70\n",
    "condition = 'moving'# # Moving, immobilized, chip\n",
    "first = True # if true, create new HDF5 file\n",
    "###############################################    \n",
    "# \n",
    "#    load data into dictionary\n",
    "#\n",
    "##############################################\n",
    "folder = '{}_{}/'.format(typ, condition)\n",
    "dataLog = '{0}_{1}/{0}_{1}_datasets.txt'.format(typ, condition)\n",
    "outLoc = \"Analysis/{}_{}_results.hdf5\".format(typ, condition)\n",
    "outLocData = \"Analysis/{}_{}.hdf5\".format(typ, condition)\n",
    "\n",
    "# data parameters\n",
    "dataPars = {'medianWindow':50, # smooth eigenworms with gauss filter of that size, must be odd\n",
    "            'gaussWindow':50, # gauss window for angle velocity derivative. Acts on full (50Hz) data\n",
    "            'rotate':False, # rotate Eigenworms using previously calculated rotation matrix\n",
    "            'windowGCamp': 6,  # gauss window for red and green channel\n",
    "            'interpolateNans': 6,#interpolate gaps smaller than this of nan values in calcium data\n",
    "            }\n",
    "\n",
    "filename = 'datasets/AML32_moving.hdf5'\n",
    "dataSets = h5py.File(filename, 'r')\n",
    "# dataSets = dh.loadMultipleDatasets(dataLog, pathTemplate=folder, dataPars = dataPars, nDatasets = None)\n",
    "keyList = np.sort(list(dataSets.keys()))\n",
    "    \n",
    "print(keyList)\n",
    "keyList = keyList[0:3]\n",
    "# results dictionary \n",
    "resultDict = {}\n",
    "for kindex, key in enumerate(keyList):\n",
    "    resultDict[key] = {}\n",
    "# analysis parameters\n",
    "\n",
    "pars ={'nCompPCA':10, # no of PCA components\n",
    "        'PCAtimewarp':False, #timewarp so behaviors are equally represented\n",
    "        'trainingCut': 0.6, # what fraction of data to use for training \n",
    "        'trainingType': 'middle', # simple, random or middle.select random or consecutive data for training. Middle is a testset in the middle\n",
    "        'linReg': 'simple', # ordinary or ransac least squares\n",
    "        'trainingSample': 1, # take only samples that are at least n apart to have independence. 4sec = gcamp_=->24 apart\n",
    "        'useRank': 0, # use the rank transformed version of neural data for all analyses\n",
    "        'useDeconv': 0, # use the deconvolved transformed version of neural data for all analyses\n",
    "        'nCluster': 10, # use the deconvolved transformed version of neural data for all analyses\n",
    "        'useClust':False,# use clusters in the fitting procedure.\n",
    "        'useDeriv':False,# use neural activity derivative for PCA\n",
    "        'useRaw':False,# use neural R/R0\n",
    "        'testVolumes' : 6*60*1, # 2 min of data for test sets in nested validation\n",
    "        'periods': np.arange(0, 300) # relevant periods in seconds for timescale estimate\n",
    "        \n",
    "     }\n",
    "\n",
    "behaviors = ['AngleVelocity','Eigenworm3']\n",
    "#behaviors = ['Eigenworm3']\n",
    "\n",
    "###############################################    \n",
    "# \n",
    "# check which calculations to perform\n",
    "#\n",
    "##############################################\n",
    "createIndicesTest = 1#True \n",
    "overview = 1#False\n",
    "predNeur = 0\n",
    "predPCA = 0\n",
    "bta = 0\n",
    "svm = 0\n",
    "pca = 0#False\n",
    "kato_pca= 0\n",
    "half_pca= 0\n",
    "hierclust = False\n",
    "linreg = False\n",
    "periodogram = 0\n",
    "nestedvalidation = 0\n",
    "lasso = 0\n",
    "elasticnet = 1#True\n",
    "lagregression = 0\n",
    "positionweights = 0#True\n",
    "resultsPredictionOverview = 1\n",
    "transient = 0\n",
    "###############################################    \n",
    "# \n",
    "# create training and test set indices\n",
    "# \n",
    "##############################################\n",
    "if createIndicesTest:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        resultDict[key] = {'Training':{}}\n",
    "        for label in behaviors:\n",
    "            train, test = dr.createTrainingTestIndices(dataSets[key], pars, label=label)\n",
    "            if transient:\n",
    "               train = np.where(dataSets[key]['Neurons']['Time']<4*60)[0]\n",
    "                # after 4:30 min\n",
    "               test = np.where((dataSets[key]['Neurons']['Time']>7*60)*(dataSets[key]['Neurons']['Time']<14*60))[0]\n",
    "               resultDict[key]['Training']['Half'] ={'Train':train}\n",
    "               resultDict[key]['Training']['Half']['Test'] = test\n",
    "            else:\n",
    "                 # add half split\n",
    "                midpoint = np.mean(dataSets[key]['Neurons']['Time'])\n",
    "                trainhalf = np.where(dataSets[key]['Neurons']['Time']<midpoint)[0]\n",
    "                testhalf = np.where(dataSets[key]['Neurons']['Time']>midpoint)[0]\n",
    "                resultDict[key]['Training']['Half'] ={'Train':trainhalf}\n",
    "                resultDict[key]['Training']['Half']['Test'] = testhalf\n",
    "            resultDict[key]['Training'][label] = {'Train':train  }\n",
    "            resultDict[key]['Training'][label]['Test']=test\n",
    "           \n",
    "\n",
    "    print(\"Done generating trainingsets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################    \n",
    "# \n",
    "# some generic data checking plots\n",
    "#\n",
    "##############################################\n",
    "if overview:\n",
    "        # line plots of neuronal activity, pretty\n",
    "    mp.neuralActivity(dataSets, keyList)\n",
    "        # cimple scatter of behavior versus neurons\n",
    "    #mp.plotBehaviorNeuronCorrs(dataSets, keyList, behaviors)\n",
    "        # heatmaps of neuronal activity ordered by behavior\n",
    "    mp.plotBehaviorOrderedNeurons(dataSets, keyList, behaviors)\n",
    "        # sanity check - CMS velocity, wave velocity and turn variables with ethogram\n",
    "    mp.plotVelocityTurns(dataSets, keyList)\n",
    "        # plot neural data, ethogram, behavior and location for each dataset\n",
    "    mp.plotDataOverview(dataSets, keyList)\n",
    "        # neuron locations\n",
    "    #mp.plotNeurons3D(dataSets, keyList, threed = False)  \n",
    "    #mp.plotExampleCenterlines(dataSets, keyList, folder)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################    \n",
    "# \n",
    "# predict neural dynamics from behavior\n",
    "#\n",
    "##############################################\n",
    "if predPCA:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('predicting neural dynamics from behavior')\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['PCAPred'] = dr.predictBehaviorFromPCA(dataSets[key], \\\n",
    "                    splits, pars, behaviors)\n",
    "    \n",
    "###############################################    \n",
    "# \n",
    "# predict neural dynamics from behavior\n",
    "#\n",
    "##############################################\n",
    "if predNeur:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('predicting neural dynamics from behavior')\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['RevPred'] = dr.predictNeuralDynamicsfromBehavior(dataSets[key], \\\n",
    "                    splits, pars, useFullNeurons=False)\n",
    "        mp.plotNeuronPredictedFromBehavior(resultDict[key], dataSets[key])\n",
    "        plt.show()\n",
    "###############################################    \n",
    "# \n",
    "# use agglomerative clustering to connect similar neurons\n",
    "#\n",
    "##############################################\n",
    "if hierclust:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('running clustering')\n",
    "        resultDict[key]['clust'] = dr.runHierarchicalClustering(dataSets[key], pars)\n",
    "        \n",
    "###############################################    \n",
    "# \n",
    "# calculate the periodogram of the neural signals\n",
    "#\n",
    "##############################################\n",
    "if periodogram:\n",
    "    print('running periodogram(s)')\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        resultDict[key]['Period'] = dr.runPeriodogram(dataSets[key], pars, testset = None)       \n",
    "###############################################    \n",
    "# \n",
    "# use behavior triggered averaging to create non-othogonal axes\n",
    "#\n",
    "##############################################\n",
    "if bta:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('running BTA')\n",
    "        resultDict[key]['BTA'] =dr.runBehaviorTriggeredAverage(dataSets[key], pars)\n",
    "    mp.plotPCAresults(dataSets, resultDict, keyList, pars,  flag = 'BTA')\n",
    "    plt.show()\n",
    "    mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'etho', flag = 'BTA')\n",
    "    plt.show()\n",
    "    ###############################################    \n",
    "# \n",
    "# use svm to predict discrete behaviors\n",
    "#\n",
    "##############################################\n",
    "if svm:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('running SVM')\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['SVM'] = dr.discreteBehaviorPrediction(dataSets[key], pars, splits )\n",
    "    \n",
    "    \n",
    "    # overview of SVM results and weights\n",
    "    mp.plotPCAresults(dataSets, resultDict, keyList, pars,  flag = 'SVM')\n",
    "    plt.show()\n",
    "    #  plot 3D trajectory of SVM\n",
    "    mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'etho', flag = 'SVM')\n",
    "    plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'time',  flag = 'SVM')\n",
    "#        plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'velocity',  flag = 'SVM')\n",
    "#        plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'turns',  flag = 'SVM')\n",
    "#        plt.show()\n",
    "\n",
    "###############################################    \n",
    "# \n",
    "# run PCA and store results\n",
    "#\n",
    "##############################################\n",
    "#%%\n",
    "if pca:\n",
    "    print('running PCA')\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        resultDict[key]['PCA'] = dr.runPCANormal(dataSets[key], pars)\n",
    "\n",
    "    # overview of data ordered by PCA\n",
    "    mp.plotDataOverview2(dataSets, keyList, resultDict)\n",
    "    # overview of PCA results and weights\n",
    "    mp.plotPCAresults(dataSets, resultDict, keyList, pars)\n",
    "    plt.show()\n",
    "    \n",
    "    mp.plotPCANoise(resultDict, keyList)\n",
    "\n",
    "    # show correlates of PCA\n",
    "    #mp.plotPCAcorrelates(dataSets, resultDict, keyList, pars, flag='PCA')\n",
    "    #  plot 3D trajectory of PCA\n",
    "    mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'etho')\n",
    "#    plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'time')\n",
    "#        plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'velocity')\n",
    "#        plt.show()\n",
    "#        mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'turns')\n",
    "#        plt.show()\n",
    "###############################################    \n",
    "# \n",
    "# run Kato PCA\n",
    "#\n",
    "##############################################\n",
    "#%%\n",
    "if kato_pca:\n",
    "    print('running Kato et. al PCA')\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        resultDict[key]['katoPCA'] = dr.runPCANormal(dataSets[key], pars, deriv = True)\n",
    "    \n",
    "    # overview of PCA results and weights\n",
    "    mp.plotPCAresults(dataSets, resultDict, keyList, pars, flag='katoPCA')\n",
    "    plt.show()\n",
    "    \n",
    "   \n",
    "    # show correlates of PCA\n",
    "    mp.plotPCAcorrelates(dataSets, resultDict, keyList, pars, flag='katoPCA')\n",
    "    #  plot 3D trajectory of PCA\n",
    "    mp.plotPCAresults3D(dataSets, resultDict, keyList, pars, col = 'etho', flag='katoPCA')\n",
    "    plt.show()\n",
    "###############################################    \n",
    "# \n",
    "# run split first-second half PCA\n",
    "#\n",
    "##############################################\n",
    "#%%\n",
    "if half_pca:\n",
    "    print('half-split PCA')\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        # run PCA on each half\n",
    "        splits = resultDict[key]['Training']\n",
    "        \n",
    "        resultDict[key]['PCAHalf1'] = dr.runPCANormal(dataSets[key], pars, whichPC=0, testset = splits['Half']['Train'])\n",
    "        resultDict[key]['PCAHalf2'] = dr.runPCANormal(dataSets[key], pars, whichPC=0, testset =splits['Half']['Test'])\n",
    "        resultDict[key]['PCArankCorr'] = dr.rankCorrPCA(resultDict[key])\n",
    "    \n",
    "################################################    \n",
    "## \n",
    "## estimate noise level pca shuffle\n",
    "##\n",
    "###############################################\n",
    "##%%\n",
    "#print 'estimate PCA noise level'\n",
    "#if pca_noise:\n",
    "#    for kindex, key in enumerate(keyList):\n",
    "#        # run PCA on each half\n",
    "#        splits = resultDict[key]['Training']\n",
    "#        resultDict[key]['PCANoise'] = dr.runPCANoiseLevelEstimate(dataSets[key], pars)\n",
    "#        resultDict[key]['PCAHalf1Noise'] = dr.runPCANoiseLevelEstimate(dataSets[key], pars, testset = splits['Half']['Train'])\n",
    "#        resultDict[key]['PCAHalf2Noise'] = dr.runPCANoiseLevelEstimate(dataSets[key], pars,  testset =splits['Half']['Test'])\n",
    "#    mp.plotPCANoise(resultDict, keyList)\n",
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "# linear regression single neurons\n",
    "#\n",
    "##############################################\n",
    "if linreg:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['Linear Regression'] = dr.linearRegressionSingleNeuron(dataSets[key], pars, splits)\n",
    "    \n",
    "    mp.plotLinearPredictionSingleNeurons(dataSets, resultDict, keyList)\n",
    "    plt.show()\n",
    "\n",
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "# linear regression using LASSO\n",
    "#\n",
    "##############################################\n",
    "if lasso:\n",
    "    print(\"Performing LASSO.\",)\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print(key)\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['LASSO'] = dr.runLasso(dataSets[key], pars, splits, plot=1, behaviors = behaviors)\n",
    "        # calculate how much more neurons contribute\n",
    "        tmpDict = dr.scoreModelProgression(dataSets[key], resultDict[key],splits, pars, fitmethod = 'LASSO', behaviors = behaviors)\n",
    "        for tmpKey in tmpDict.keys():\n",
    "            resultDict[key]['LASSO'][tmpKey].update(tmpDict[tmpKey])\n",
    "#            # reorganize to get similar structure as PCA\n",
    "#            tmpDict = dr.reorganizeLinModel(dataSets[key], resultDict[key], splits, pars, fitmethod = 'LASSO', behaviors = behaviors)\n",
    "#            for tmpKey in tmpDict.keys():\n",
    "#                resultDict[key]['LASSO'][tmpKey]=tmpDict[tmpKey]\n",
    "#            \n",
    "#        # do converse calculation -- give it only the neurons non-zero in previous case\n",
    "#        subset = {}\n",
    "        subset['AngleVelocity'] = np.where(resultDict[key]['LASSO']['Eigenworm3']['weights']>0)[0]\n",
    "        subset['Eigenworm3'] = np.where(resultDict[key]['LASSO']['AngleVelocity']['weights']>0)[0]\n",
    "        resultDict[key]['LASSO']['ConversePrediction'] = dr.runLinearModel(dataSets[key], resultDict[key], pars, splits, plot = True, behaviors = ['AngleVelocity', 'Eigenworm3'], fitmethod = 'LASSO', subset = subset)\n",
    "#        # find non-linearity\n",
    "        #dr.fitNonlinearity(dataSets[key], resultDict[key], splits, pars, fitmethod = 'LASSO', behaviors = ['AngleVelocity', 'Eigenworm3'])\n",
    "    \n",
    "    mp.plotLinearModelResults(dataSets, resultDict, keyList, pars, fitmethod='LASSO', behaviors = behaviors, random = pars['trainingType'])\n",
    "    plt.show()\n",
    "    # predict opposites\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "# linear regression using elastic Net\n",
    "#\n",
    "##############################################\n",
    "if elasticnet:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('Running Elastic Net',  key)\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['ElasticNet'] = dr.runElasticNet(dataSets[key], pars,splits, plot=1, behaviors = behaviors)\n",
    "        # calculate how much more neurons contribute\n",
    "        tmpDict = dr.scoreModelProgression(dataSets[key], resultDict[key], splits,pars, fitmethod = 'ElasticNet', behaviors = behaviors, )\n",
    "        for tmpKey in tmpDict.keys():\n",
    "            resultDict[key]['ElasticNet'][tmpKey].update(tmpDict[tmpKey])\n",
    "            \n",
    "        # do converse calculation -- give it only the neurons non-zero in previous case\n",
    "        subset = {}\n",
    "        subset['AngleVelocity'] = np.where(np.abs(resultDict[key]['ElasticNet']['Eigenworm3']['weights'])>0)[0]\n",
    "        subset['Eigenworm3'] = np.where(np.abs(resultDict[key]['ElasticNet']['AngleVelocity']['weights'])>0)[0]\n",
    "        resultDict[key]['ElasticNet']['ConversePrediction'] = dr.runLinearModel(dataSets[key], resultDict[key], pars, splits, plot = True, behaviors = ['AngleVelocity', 'Eigenworm3'], fitmethod = 'ElasticNet', subset = subset)\n",
    "        \n",
    "    mp.plotLinearModelResults(dataSets, resultDict, keyList, pars, fitmethod='ElasticNet', behaviors = behaviors,random = pars['trainingType'])\n",
    "    plt.show(block=True)\n",
    "\n",
    " #%%\n",
    "###############################################    \n",
    "# \n",
    "# lag-time fits of neural activity\n",
    "#\n",
    "##############################################\n",
    "if lagregression:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('Running lag calculation',  key)\n",
    "        splits = resultDict[key]['Training']\n",
    "        #resultDict[key]['LagLASSO'] = dr.timelagRegression(dataSets[key], pars, splits, plot = False, behaviors = ['AngleVelocity', 'Eigenworm3'], lags = np.arange(-18,19, 3))\n",
    "        resultDict[key]['LagEN'] = dr.timelagRegression(dataSets[key], pars, splits, plot = False, behaviors = ['AngleVelocity', 'Eigenworm3'], lags = np.arange(-18,19, 3), flag='ElasticNet')\n",
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "#day-forward crossvalidation for test error estimates\n",
    "#\n",
    "##############################################\n",
    "if nestedvalidation:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('Running nested validation',  key)\n",
    "        splits = resultDict[key]['Training']\n",
    "        resultDict[key]['nestedLASSO'] = dr.NestedRegression(dataSets[key], pars, splits, plot = False, behaviors = ['AngleVelocity', 'Eigenworm3'], flag = 'LASSO')    \n",
    "\n",
    "\n",
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "# overlay neuron projections with relevant neurons\n",
    "#\n",
    "##############################################\n",
    "if positionweights:\n",
    "    for kindex, key in enumerate(keyList):\n",
    "        print('plotting linear model weights on positions',  key)\n",
    "        \n",
    "    mp.plotWeightLocations(dataSets, resultDict, keyList, fitmethod='ElasticNet')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "###############################################    \n",
    "# \n",
    "# plot the number of neurons and scatter plot of predictions fo velocity and turns\n",
    "#\n",
    "##############################################\n",
    "if resultsPredictionOverview:\n",
    "    fitmethod = 'ElasticNet'\n",
    "    mp.plotLinearModelScatter(dataSets, resultDict, keyList, pars, fitmethod=fitmethod, behaviors = ['AngleVelocity', 'Eigenworm3'], random = 'none')\n",
    "    # collect the relevant number of neurons\n",
    "    \n",
    "    \n",
    "    noNeur = []\n",
    "    for key in keyList:\n",
    "        noNeur.append([resultDict[key][fitmethod]['AngleVelocity']['noNeurons'], resultDict[key][fitmethod]['Eigenworm3']['noNeurons']])\n",
    "    noNeur = np.array(noNeur)\n",
    "    plt.figure()\n",
    "    plt.bar([1,2], np.mean(noNeur, axis=0),yerr=np.std(noNeur, axis=0) )\n",
    "    plt.scatter(np.ones(len(noNeur[:,0]))+0.5, noNeur[:,0])\n",
    "    plt.scatter(np.ones(len(noNeur[:,0]))+1.5, noNeur[:,1])\n",
    "    plt.xticks([1,2], ['velocity', 'Turns'])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
